<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zhengtong Xu</title>

    <meta name="author" content="Zhengtong Xu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zhengtong Xu    徐政通
                </p>
                <p>I'm a third-year PhD Student at <a href="https://www.purdue.edu/">Purdue University</a>, advised by Professor <a href="https://www.purduemars.com/">Yu She</a>.
                </p>
                <p>
                  I received my Bachelor's degree in mechanical engineering at <a href="https://english.hust.edu.cn/"> Huazhong University of Science and Technology</a>.
                </p>
                <p style="text-align:center">
                  <a href="xu1703@purdue.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/zhengtong-xu-4287b8174/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=nfwA3RUAAAAJ&hl=en">G. Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/XuZhengtong">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ZhengtongXu">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/photo.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research aims to develop robots capable of performing everyday manipulation tasks with human-level capabilities. Towards this goal, my focus is on generative models in robotics, imitation learning, and multi-sensory robot manipulation.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
              <video playsinline autoplay loop muted src="images/letac_mpc_teaser.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
              </a></td>
              <td width="60%" valign="top">
                <p>
                  <span class="papertitle">LeTac-MPC: Learning Model Predictive Control for Tactile-reactive Grasping</span>
                  <br>
                    <strong>Zhengtong Xu</strong>, Yu She
                  <br>
                  <em>Accepted by IEEE T-RO</em>, 2024
                  <br>
                </p>

                <a href="https://arxiv.org/abs/2403.04934">arXiv</a> /
                <a href="https://drive.google.com/file/d/1rDwg7dA3Wfhhb3rhry0cIfAxGli7WT7k/view">video</a> /
                <a href="https://github.com/ZhengtongXu/LeTac-MPC">code</a> /
                <a href="#" onclick="toggleBibtex(event, 'LeTac'); return false;">bibtex</a>

                <div id="LeTac" style="display:none; position:absolute; background-color:white; border:1px solid #ccc; padding:10px; width:400px; z-index:100; border-radius:15px; overflow:auto; word-wrap:break-word;">
                  <pre style="margin:0;">
                    @article{xu2024letac,
                      title={LeTac-MPC: Learning Model Predictive Control for Tactile-reactive Grasping},
                      author={Xu, Zhengtong and She, Yu},
                      journal={arXiv preprint arXiv:2403.04934},
                      year={2024}
                    }
                  </pre>
                  <a href="#" onclick="toggleBibtex(event, 'LeTac'); return false;">Close</a>
                </div>

                <p></p>
                <p>
                  A generalizable end-to-end tactile-reactive grasping controller with differentiable MPC, combining learning and model-based approaches.  
                </p>
              </td>
            </tr>
            <tr>
              <td width="40%" valign="top" align="center">
              <video playsinline autoplay loop muted src="images/ChickenLegsHangingUniTVis.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
              </a></td>
              <td width="60%" valign="top">
                <p>
                  <span class="papertitle">UniT: Unified Tactile Representation for Robot Learning</span>
                  <br>
                    <strong>Zhengtong Xu</strong>, Raghava Uppuluri, Xinwei Zhang, Cael Fitch, Philip Glen Crandall, Wan Shou, Dongyi Wang, Yu She
                  <br>
                  <em>Under Review</em>, 2024
                  <br>
                </p>

                <a href="https://zhengtongxu.github.io/unifiedtactile.github.io/">website</a> /
                <a href="https://www.arxiv.org/abs/2408.06481">arXiv</a> /
                <a href="https://drive.google.com/file/d/1RrW7xk7SjMaIHqksxg0vrhm7SPVrPtg8/view">video</a> /
                <a href="https://github.com/ZhengtongXu/UniT">code</a> /
                <a href="#" onclick="toggleBibtex(event, 'UniT'); return false;">bibtex</a>

                <div id="UniT" style="display:none; position:absolute; background-color:white; border:1px solid #ccc; padding:10px; width:400px; z-index:100; border-radius:15px; overflow:auto; word-wrap:break-word;">
                  <pre style="margin:0;">
                    @article{xu2024unit,
                      title={UniT: Unified Tactile Representation for Robot Learning},
                      author={Xu, Zhengtong and Uppuluri, Raghava and Zhang, Xinwei and Fitch, Cael and Crandall, Philip Glen and Shou, Wan and Wang, Dongyi and She, Yu},
                      journal={arXiv preprint arXiv:2408.06481},
                      year={2024}
                    }
                  </pre>
                  <a href="#" onclick="toggleBibtex(event, 'UniT'); return false;">Close</a>
                </div>
                
                <p></p>
                <p>
                  Learn a unified tactile representation with transferability and generalizability only by a single simple object.
                </p>
              </td>
            </tr>
            <tr>
              <td width="40%" valign="top" align="center">
              <video playsinline autoplay loop muted src="images/vilp_teaser.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
              </a></td>
              <td width="60%" valign="top">
                <p>
                  <span class="papertitle">VILP: Imitation Learning with Latent Video Planning</span>
                  <br>
                    <strong>Zhengtong Xu</strong>, Qiang Qiu, Yu She
                  <br>
                  <em>Under Review</em>, 2024
                  <br>
                </p>

                <a href="">arXiv(soon)</a> /
                <a href="">video(soon)</a> /
                <a href="https://github.com/ZhengtongXu/VILP">code</a>

                
                <p></p>
                <p>
                  VILP integrates the video generation model into policies, enabling the representation of multi-modal action distributions while reducing reliance on extensive high-quality robot action data.
                </p>
              </td>
            </tr>
            <tr>
              <td width="40%" valign="top" align="center">
              <video playsinline autoplay loop muted src="images/leto_teaser.mp4" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
              </a></td>
              <td width="60%" valign="top">
                <p>
                  <span class="papertitle">LeTO: Learning Constrained Visuomotor Policy with Differentiable Trajectory Optimization</span>
                  <br>
                    <strong>Zhengtong Xu</strong>, Yu She
                  <br>
                  <em>Under Review</em>, 2024
                  <br>
                </p>

                <a href="https://arxiv.org/abs/2401.17500">arXiv</a> /
                <a href="https://drive.google.com/file/d/1-Ty2JRg8COrHM_cl0vaj-xSGzjnZOg7L/view">video</a> /
                <a href="https://github.com/ZhengtongXu/LeTO">code</a> /
                <a href="#" onclick="toggleBibtex(event, 'LeTO'); return false;">bibtex</a>

                <div id="LeTO" style="display:none; position:absolute; background-color:white; border:1px solid #ccc; padding:10px; width:400px; z-index:100; border-radius:15px; overflow:auto; word-wrap:break-word;">
                  <pre style="margin:0;">
                    @article{xu2024leto,
                      title={LeTO: Learning Constrained Visuomotor Policy with Differentiable Trajectory Optimization},
                      author={Xu, Zhengtong and She, Yu},
                      journal={arXiv preprint arXiv:2401.17500},
                      year={2024}
                    }
                  </pre>
                  <a href="#" onclick="toggleBibtex(event, 'LeTO'); return false;">Close</a>
                </div>
                
                <p></p>
                <p>
                  LeTO is a `gray box" method which marries optimization-based safety and interpretability with representational abilities of neural networks.
                </p>
              </td>
            </tr>
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/vistac.png" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;">
              </td>
              <td width="60%" valign="top">
                <p>
                  <span class="papertitle">VisTac: Toward a Unified Multimodal Sensing Finger for Robotic Manipulation</span>
                  <br>
                  Sheeraz Athar<sup>*</sup>,  Gaurav Patel<sup>*</sup>, <strong>Zhengtong Xu</strong>, Qiang Qiu, Yu She
                  <br>
                  <em>IEEE Sensors Journal</em>, 2023
                  <br>
                </p>

                <a href="https://ieeexplore.ieee.org/document/10242327">paper</a> /
                <a href="https://www.youtube.com/watch?v=SLN2gQ_haYs">video</a> /
                <a href="#" onclick="toggleBibtex(event, 'Vistac'); return false;">bibtex</a>

                <div id="Vistac" style="display:none; position:absolute; background-color:white; border:1px solid #ccc; padding:10px; width:400px; z-index:100; border-radius:15px; overflow:auto; word-wrap:break-word;">
                  <pre style="margin:0;">
                    @article{athar2023vistac,
                      title={Vistac towards a unified multi-modal sensing finger for robotic manipulation},
                      author={Athar, Sheeraz and Patel, Gaurav and Xu, Zhengtong and Qiu, Qiang and She, Yu},
                      journal={IEEE Sensors Journal},
                      year={2023},
                      publisher={IEEE}
                    }
                  </pre>
                  <a href="#" onclick="toggleBibtex(event, 'Vistac'); return false;">Close</a>
                </div>
                
                <p></p>
                <p>
                  VisTac seamlessly combines high-resolution tactile and visual perception in a single unified device.
                </p>
              </td>
            </tr>
          </table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Awards</h2>
                  <ul>
                    <li><strong>Dr. Theodore J. and Isabel M. Williams Fellowship</strong>, Purdue University, 2022</li>
                    <li><strong>Chinese National Scholarship</strong>,  Ministry of Education of China, 2017</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Teaching</h2>
                  <ul>
                    <li><strong>Vertically Integrated Projects (VIP)-GE Robotics and Autonomous Systems</strong>, Grad Mentor, Spring 2024/Fall 2023/Summer 2023</li>
                    <li><strong>IE 474-Industrial Control Systems</strong>,  Teaching Assistant, Fall 2022</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
    <script>
      function toggleBibtex(event, bibtexId) {
        var bibtexDiv = document.getElementById(bibtexId);
        if (bibtexDiv.style.display === 'none') {
          var x = event.pageX;
          var y = event.pageY;
          
          bibtexDiv.style.left = x + 'px';
          bibtexDiv.style.top = y + 'px';
          
          bibtexDiv.style.display = 'block';
        } else {
          bibtexDiv.style.display = 'none';
        }
      }
    </script>
  </body>
</html>
